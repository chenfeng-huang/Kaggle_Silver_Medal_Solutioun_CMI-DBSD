## Child Mind Institute â€” Detect Behavior with Sensor Data (CMIâ€‘DBSD) Solution
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Python](https://img.shields.io/badge/pytorch2.8+-orange.svg)

This solution was developed for the Kaggle competition [Child Mind Institute â€” Detect Behavior with Sensor Data](https://www.kaggle.com/competitions/cmi-detect-behavior-with-sensor-data), where participants classify wristâ€‘worn multimodal sensor sequences into fineâ€‘grained gesture classes relevant to BFRBâ€‘like behaviors. The approach engineers IMU orientationâ€‘aware features, aggregates ToF/thermopile signals, and trains a twoâ€‘branch temporal CNN with a modality gate and metric learning. A subjectâ€‘level global assignment postâ€‘processing improves class diversity across sequences.

Our work earned a Silver Medal. The repository contains endâ€‘toâ€‘end training and an inference server compatible with Kaggleâ€™s evaluation API. ðŸ¥ˆ

![CMIâ€‘DBSD â€” Silver Medal](./certificate.png)

## Competition Overview

### Competition Introduction

The goal is to predict the gesture class for each sequence recorded by a Helios wrist device with multimodal sensors:
- IMU (accelerometer, quaternion orientation) at high frequency
- Thermopile (THM) temperature sensors
- Timeâ€‘ofâ€‘Flight (ToF) distance sensors (5 modules Ã— 64 pixels)

The official evaluation is a hierarchical macroâ€‘averaged F1, implemented here as an equalâ€‘weight average of:
- Binary F1: target (BFRBâ€‘like) vs nonâ€‘target
- Multiclass macro F1: target classes kept separate; all nonâ€‘target merged to `non_target`

### Competition Background

Detecting BFRBâ€‘like behaviors from wrist sensors requires robust orientation handling, denoising, and crossâ€‘modal fusion. A practical pipeline must:
- Align across left/right handedness
- Derive linear acceleration and angular kinematics from quaternions
- Summarize highâ€‘dimensional ToF pixels safely (handle noâ€‘return values)
- Train sequence models without subject leakage and optimize temporal receptive fields

## Solution Overview

This solution comprises four components:

1. **Feature Engineering**
   - Remove gravity from `acc_[x,y,z]` using quaternion `rot_[x,y,z,w]` to get linear acceleration.
   - Derive angular velocity and angular distance from quaternion sequences.
   - Aggregate ToF per sensor (`mean,std,min,max` over 64 pixels with `-1 â†’ NaN` handling) and include raw THM.

2. **Twoâ€‘Branch CNN with Modality Gate**
   - IMU branch splits into accelerationâ€‘related and rotationâ€‘related subâ€‘branches with residual SEâ€‘CNN blocks.
   - ToF/THM branch uses residual SEâ€‘CNN; a learned scalar gate downâ€‘weights noisy ToF/THM.
   - Fused backbone â†’ global pooling â†’ dense head for classification; also returns a 128â€‘d embedding.

3. **Training Protocol**
   - StratifiedGroupKFold (n=5) stratified by `sequence_type`, grouped by `subject` to prevent leakage.
   - Loss: soft crossâ€‘entropy + triplet margin loss (hard mining) + gate supervision via BCE (randomly masked ToF/THM in collate).
   - Cosine LR with warmup; bestâ€‘perâ€‘fold checkpoints saved.

4. **Inference with Global Assignment**
   - Average logits across 5 fold models; compute logâ€‘probs per sequence.
   - For each subject, apply the Hungarian algorithm on the (sequences Ã— classes) logâ€‘prob matrix to promote uniqueâ€‘class assignments across that subjectâ€™s sequences.

The final output per sequence is a fineâ€‘grained gesture label.


## How to Reproduce

### Environment Setup

- Python 3.10+ recommended
- Install dependencies:

```bash
pip install -r requirements.txt
```


### Data Layout

Place the competition CSVs under `data/`:

```
data/
â”œâ”€ train.csv
â”œâ”€ test.csv
â”œâ”€ train_demographics.csv
â””â”€ test_demographics.csv
```

Notes:
- Timeâ€‘series columns include IMU (`acc_*`, `rot_*` quaternions), THM (`thm_*`), and ToF pixels (`tof_[1..5]_v0..v63`).
- `-1` in ToF pixels denotes noâ€‘return; handled as `NaN` before aggregation.

### Training

Run endâ€‘toâ€‘end training with 5â€‘fold CV and artefact export:

```bash
python train.py
```

Outputs are saved to `artifacts/`:
- `scaler.pkl`, `sequence_maxlen.npy`, `feature_cols.npy`, `gesture_classes.npy`
- `gesture_two_branch_fold{0..4}.pth`

### Inference

- Kaggle submission workflow (recommended):
  - Upload `artifacts/` as a Kaggle Dataset (e.g., `cmi-dbsd-models`).
  - In a Kaggle Notebook, attach that dataset; run `inference.py` to serve via the provided gateway.
- Local smoke test:
  - `inference.py` is built for Kaggle mounts (`/kaggle/input/...`). For local runs, adapt paths or replicate Kaggleâ€™s input layout.

## Files and Structure

- `train.py`: Training pipeline, feature engineering, CV, and model saving
- `inference.py`: Artefact loading, perâ€‘sequence prediction, subjectâ€‘level assignment, Kaggle gateway
- `model.py`: Twoâ€‘branch temporal CNN with SE blocks and ToF gate
- `dataset.py`: Dataset/augmentations, padding/collate with ToF masking
- `helpers.py`: Quaternionâ€‘aware feature utilities and padding
- `metric.py`: Official hierarchical F1 implementation used for monitoring
- `artifacts/`: Saved scaler, feature metadata, class list, and fold checkpoints

## Data Source and Citation

- See `data/data_source.md` and the Kaggle competition page for rules and data access.

```bibtex
@misc{cmi-detect-behavior-with-sensor-data,
    author = {Laura Newman, David LoBue, Arianna Zuanazzi, Florian Rupprecht, Luke Mears, Roxanne McAdams, Erin Brown, Yanyi Wang, Camilla Strauss, Arno Klein, Lauren Hendrix, Maki Koyama, Josh To, Curt White, Yuki Kotani, Michelle Freund, Michael Milham, Gregory Kiar, Martyna Plomecka, Sohier Dane, and Maggie Demkin},
    title = {CMI - Detect Behavior with Sensor Data},
    year = {2025},
    howpublished = {\url{https://kaggle.com/competitions/cmi-detect-behavior-with-sensor-data}},
    note = {Kaggle}
}
```

## Author

Maintainer: Chenfeng Huang â€” [Kaggle](https://www.kaggle.com/alrickh)

For questions, please open an issue or discussion in this repository.

## License

Distributed under the terms of the license in `LICENSE`.
